{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['start.ipynb', '--algorithm', 'IGA', '--dataset', 'RotatedMNIST', '--test_env', '2']\n",
    "# python3 -m domainbed.scripts.train --data_dir=./domainbed/data/MNIST/ --algorithm IGA --dataset ColoredMNIST --test_env 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n",
    "\n",
    "import argparse\n",
    "import collections\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import domainbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from domainbed import datasets\n",
    "from domainbed import hparams_registry\n",
    "from domainbed import algorithms\n",
    "from domainbed.lib import misc\n",
    "from domainbed.lib.fast_data_loader import InfiniteDataLoader, FastDataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Domain generalization')\n",
    "    parser.add_argument('--data_dir', type=str, default='./domainbed/data')\n",
    "    parser.add_argument('--dataset', type=str, default=\"RotatedMNIST\")\n",
    "    parser.add_argument('--algorithm', type=str, default=\"ERM\")\n",
    "    parser.add_argument('--task', type=str, default=\"domain_generalization\",\n",
    "        choices=[\"domain_generalization\", \"domain_adaptation\"])\n",
    "    parser.add_argument('--hparams', type=str,\n",
    "        help='JSON-serialized hparams dict')\n",
    "    parser.add_argument('--hparams_seed', type=int, default=0,\n",
    "        help='Seed for random hparams (0 means \"default hparams\")')\n",
    "    parser.add_argument('--trial_seed', type=int, default=0,\n",
    "        help='Trial number (used for seeding split_dataset and '\n",
    "        'random_hparams).')\n",
    "    parser.add_argument('--seed', type=int, default=0,\n",
    "        help='Seed for everything else')\n",
    "    parser.add_argument('--steps', type=int, default=None,\n",
    "        help='Number of steps. Default is dataset-dependent.')\n",
    "    parser.add_argument('--checkpoint_freq', type=int, default=None,\n",
    "        help='Checkpoint every N steps. Default is dataset-dependent.')\n",
    "    parser.add_argument('--test_envs', type=int, nargs='+', default=[0])\n",
    "    parser.add_argument('--output_dir', type=str, default=\"train_output\")\n",
    "    parser.add_argument('--holdout_fraction', type=float, default=0.2)\n",
    "    parser.add_argument('--uda_holdout_fraction', type=float, default=0,\n",
    "        help=\"For domain adaptation, % of test to use unlabeled for training.\")\n",
    "    parser.add_argument('--skip_model_save', action='store_true')\n",
    "    parser.add_argument('--save_model_every_checkpoint', action='store_true')\n",
    "    args = parser.parse_args()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment:\n",
      "\tPython: 3.9.7\n",
      "\tPyTorch: 1.8.1+cu101\n",
      "\tTorchvision: 0.9.1+cu101\n",
      "\tCUDA: 10.1\n",
      "\tCUDNN: 7603\n",
      "\tNumPy: 1.19.5\n",
      "\tPIL: 8.3.2\n"
     ]
    }
   ],
   "source": [
    "    # If we ever want to implement checkpointing, just persist these values\n",
    "    # every once in a while, and then load them from disk here.\n",
    "    start_step = 0\n",
    "    algorithm_dict = None\n",
    "\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "    sys.stdout = misc.Tee(os.path.join(args.output_dir, 'out.txt'))\n",
    "    sys.stderr = misc.Tee(os.path.join(args.output_dir, 'err.txt'))\n",
    "\n",
    "    print(\"Environment:\")\n",
    "    print(\"\\tPython: {}\".format(sys.version.split(\" \")[0]))\n",
    "    print(\"\\tPyTorch: {}\".format(torch.__version__))\n",
    "    print(\"\\tTorchvision: {}\".format(torchvision.__version__))\n",
    "    print(\"\\tCUDA: {}\".format(torch.version.cuda))\n",
    "    print(\"\\tCUDNN: {}\".format(torch.backends.cudnn.version()))\n",
    "    print(\"\\tNumPy: {}\".format(np.__version__))\n",
    "    print(\"\\tPIL: {}\".format(PIL.__version__))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "    print('Args:')\n",
    "    for k, v in sorted(vars(args).items()):\n",
    "        print('\\t{}: {}'.format(k, v))\n",
    "\n",
    "    if args.hparams_seed == 0:\n",
    "        hparams = hparams_registry.default_hparams(args.algorithm, args.dataset)\n",
    "    else:\n",
    "        hparams = hparams_registry.random_hparams(args.algorithm, args.dataset,\n",
    "            misc.seed_hash(args.hparams_seed, args.trial_seed))\n",
    "    if args.hparams:\n",
    "        hparams.update(json.loads(args.hparams))\n",
    "\n",
    "    print('HParams:')\n",
    "    print(args)\n",
    "    print('111')\n",
    "    for k, v in sorted(hparams.items()):\n",
    "        print('\\t{}: {}'.format(k, v))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m     device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mdataset \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mvars\u001B[39m(datasets):\n\u001B[0;32m---> 13\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mvars\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdatasets\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_envs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m\n",
      "File \u001B[0;32m~/projects/EIL/domainbed/datasets.py:160\u001B[0m, in \u001B[0;36mRotatedMNIST.__init__\u001B[0;34m(self, root, test_envs, hparams)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, root, test_envs, hparams):\n\u001B[0;32m--> 160\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mRotatedMNIST\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m45\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m75\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m                                       \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrotate_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/EIL/domainbed/datasets.py:110\u001B[0m, in \u001B[0;36mMultipleEnvironmentMNIST.__init__\u001B[0;34m(self, root, environments, dataset_transform, input_shape, num_classes)\u001B[0m\n\u001B[1;32m    108\u001B[0m     images \u001B[38;5;241m=\u001B[39m original_images[i::\u001B[38;5;28mlen\u001B[39m(environments)]\n\u001B[1;32m    109\u001B[0m     labels \u001B[38;5;241m=\u001B[39m original_labels[i::\u001B[38;5;28mlen\u001B[39m(environments)]\n\u001B[0;32m--> 110\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatasets\u001B[38;5;241m.\u001B[39mappend(\u001B[43mdataset_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menvironments\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_shape \u001B[38;5;241m=\u001B[39m input_shape\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_classes \u001B[38;5;241m=\u001B[39m num_classes\n",
      "File \u001B[0;32m~/projects/EIL/domainbed/datasets.py:172\u001B[0m, in \u001B[0;36mRotatedMNIST.rotate_dataset\u001B[0;34m(self, images, labels, angle)\u001B[0m\n\u001B[1;32m    170\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mlen\u001B[39m(images), \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m28\u001B[39m, \u001B[38;5;241m28\u001B[39m)\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(images)):\n\u001B[0;32m--> 172\u001B[0m     x[i] \u001B[38;5;241m=\u001B[39m \u001B[43mrotation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    174\u001B[0m y \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m TensorDataset(x, y)\n",
      "File \u001B[0;32m~/anaconda3/envs/EIL/lib/python3.9/site-packages/torchvision/transforms/transforms.py:60\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[0;32m---> 60\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[0;32m~/anaconda3/envs/EIL/lib/python3.9/site-packages/torchvision/transforms/transforms.py:97\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/EIL/lib/python3.9/site-packages/torchvision/transforms/functional.py:142\u001B[0m, in \u001B[0;36mto_tensor\u001B[0;34m(pic)\u001B[0m\n\u001B[1;32m    140\u001B[0m img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mpermute((\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mByteTensor):\n\u001B[0;32m--> 142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_float_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdiv(\u001B[38;5;241m255\u001B[39m)\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    if args.dataset in vars(datasets):\n",
    "        dataset = vars(datasets)[args.dataset](args.data_dir,\n",
    "            args.test_envs, hparams)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Split each env into an 'in-split' and an 'out-split'. We'll train on\n",
    "    # each in-split except the test envs, and evaluate on all splits.\n",
    "\n",
    "    # To allow unsupervised domain adaptation experiments, we split each test\n",
    "    # env into 'in-split', 'uda-split' and 'out-split'. The 'in-split' is used\n",
    "    # by collect_results.py to compute classification accuracies.  The\n",
    "    # 'out-split' is used by the Oracle model selectino method. The unlabeled\n",
    "    # samples in 'uda-split' are passed to the algorithm at training time if\n",
    "    # args.task == \"domain_adaptation\". If we are interested in comparing\n",
    "    # domain generalization and domain adaptation results, then domain\n",
    "    # generalization algorithms should create the same 'uda-splits', which will\n",
    "    # be discared at training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    in_splits = []\n",
    "    out_splits = []\n",
    "    uda_splits = []\n",
    "    for env_i, env in enumerate(dataset):\n",
    "        uda = []\n",
    "\n",
    "        out, in_ = misc.split_dataset(env,\n",
    "            int(len(env)*args.holdout_fraction),\n",
    "            misc.seed_hash(args.trial_seed, env_i))\n",
    "\n",
    "        if env_i in args.test_envs:\n",
    "            uda, in_ = misc.split_dataset(in_,\n",
    "                int(len(in_)*args.uda_holdout_fraction),\n",
    "                misc.seed_hash(args.trial_seed, env_i))\n",
    "\n",
    "        if hparams['class_balanced']:\n",
    "            in_weights = misc.make_weights_for_balanced_classes(in_)\n",
    "            out_weights = misc.make_weights_for_balanced_classes(out)\n",
    "            if uda is not None:\n",
    "                uda_weights = misc.make_weights_for_balanced_classes(uda)\n",
    "        else:\n",
    "            in_weights, out_weights, uda_weights = None, None, None\n",
    "        in_splits.append((in_, in_weights))\n",
    "        out_splits.append((out, out_weights))\n",
    "        if len(uda):\n",
    "            uda_splits.append((uda, uda_weights))\n",
    "\n",
    "    if args.task == \"domain_adaptation\" and len(uda_splits) == 0:\n",
    "        raise ValueError(\"Not enough unlabeled samples for domain adaptation.\")\n",
    "\n",
    "    train_loaders = [InfiniteDataLoader(\n",
    "        dataset=env,\n",
    "        weights=env_weights,\n",
    "        batch_size=hparams['batch_size'],\n",
    "        num_workers=dataset.N_WORKERS)\n",
    "        for i, (env, env_weights) in enumerate(in_splits)\n",
    "        if i not in args.test_envs]\n",
    "\n",
    "    uda_loaders = [InfiniteDataLoader(\n",
    "        dataset=env,\n",
    "        weights=env_weights,\n",
    "        batch_size=hparams['batch_size'],\n",
    "        num_workers=dataset.N_WORKERS)\n",
    "        for i, (env, env_weights) in enumerate(uda_splits)\n",
    "        if i in args.test_envs]\n",
    "\n",
    "    eval_loaders = [FastDataLoader(\n",
    "        dataset=env,\n",
    "        batch_size=64,\n",
    "        num_workers=dataset.N_WORKERS)\n",
    "        for env, _ in (in_splits + out_splits + uda_splits)]\n",
    "    eval_weights = [None for _, weights in (in_splits + out_splits + uda_splits)]\n",
    "    eval_loader_names = ['env{}_in'.format(i)\n",
    "        for i in range(len(in_splits))]\n",
    "    eval_loader_names += ['env{}_out'.format(i)\n",
    "        for i in range(len(out_splits))]\n",
    "    eval_loader_names += ['env{}_uda'.format(i)\n",
    "        for i in range(len(uda_splits))]\n",
    "\n",
    "    algorithm_class = algorithms.get_algorithm_class(args.algorithm)\n",
    "    algorithm = algorithm_class(dataset.input_shape, dataset.num_classes,\n",
    "        len(dataset) - len(args.test_envs), hparams)\n",
    "\n",
    "    if algorithm_dict is not None:\n",
    "        algorithm.load_state_dict(algorithm_dict)\n",
    "\n",
    "    algorithm.to(device)\n",
    "\n",
    "    train_minibatches_iterator = zip(*train_loaders)\n",
    "    uda_minibatches_iterator = zip(*uda_loaders)\n",
    "    checkpoint_vals = collections.defaultdict(lambda: [])\n",
    "\n",
    "    steps_per_epoch = min([len(env)/hparams['batch_size'] for env,_ in in_splits])\n",
    "\n",
    "    n_steps = args.steps or dataset.N_STEPS\n",
    "    checkpoint_freq = args.checkpoint_freq or dataset.CHECKPOINT_FREQ\n",
    "\n",
    "    def save_checkpoint(filename):\n",
    "        if args.skip_model_save:\n",
    "            return\n",
    "        save_dict = {\n",
    "            \"args\": vars(args),\n",
    "            \"model_input_shape\": dataset.input_shape,\n",
    "            \"model_num_classes\": dataset.num_classes,\n",
    "            \"model_num_domains\": len(dataset) - len(args.test_envs),\n",
    "            \"model_hparams\": hparams,\n",
    "            \"model_dict\": algorithm.state_dict()\n",
    "        }\n",
    "        torch.save(save_dict, os.path.join(args.output_dir, filename))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    last_results_keys = None\n",
    "    for step in range(start_step, n_steps):\n",
    "        step_start_time = time.time()\n",
    "        minibatches_device = [(x.to(device), y.to(device))\n",
    "            for x,y in next(train_minibatches_iterator)]\n",
    "        if args.task == \"domain_adaptation\":\n",
    "            uda_device = [x.to(device)\n",
    "                for x,_ in next(uda_minibatches_iterator)]\n",
    "        else:\n",
    "            uda_device = None\n",
    "        step_vals = algorithm.update(minibatches_device, uda_device)\n",
    "        checkpoint_vals['step_time'].append(time.time() - step_start_time)\n",
    "\n",
    "        for key, val in step_vals.items():\n",
    "            checkpoint_vals[key].append(val)\n",
    "\n",
    "        if (step % checkpoint_freq == 0) or (step == n_steps - 1):\n",
    "            results = {\n",
    "                'step': step,\n",
    "                'epoch': step / steps_per_epoch,\n",
    "            }\n",
    "\n",
    "            for key, val in checkpoint_vals.items():\n",
    "                results[key] = np.mean(val)\n",
    "\n",
    "            evals = zip(eval_loader_names, eval_loaders, eval_weights)\n",
    "            for name, loader, weights in evals:\n",
    "                acc = misc.accuracy(algorithm, loader, weights, device)\n",
    "                results[name+'_acc'] = acc\n",
    "\n",
    "            results['mem_gb'] = torch.cuda.max_memory_allocated() / (1024.*1024.*1024.)\n",
    "\n",
    "            results_keys = sorted(results.keys())\n",
    "            if results_keys != last_results_keys:\n",
    "                misc.print_row(results_keys, colwidth=12)\n",
    "                last_results_keys = results_keys\n",
    "            misc.print_row([results[key] for key in results_keys],\n",
    "                colwidth=12)\n",
    "\n",
    "            results.update({\n",
    "                'hparams': hparams,\n",
    "                'args': vars(args)\n",
    "            })\n",
    "\n",
    "            epochs_path = os.path.join(args.output_dir, 'results.jsonl')\n",
    "            with open(epochs_path, 'a') as f:\n",
    "                f.write(json.dumps(results, sort_keys=True) + \"\\n\")\n",
    "\n",
    "            algorithm_dict = algorithm.state_dict()\n",
    "            start_step = step + 1\n",
    "            checkpoint_vals = collections.defaultdict(lambda: [])\n",
    "\n",
    "            if args.save_model_every_checkpoint:\n",
    "                save_checkpoint(f'model_step{step}.pkl')\n",
    "\n",
    "    save_checkpoint('model.pkl')\n",
    "\n",
    "    with open(os.path.join(args.output_dir, 'done'), 'w') as f:\n",
    "        f.write('done')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python397jvsc74a57bd028368a58b057c9a04cabb17d26aeb2aa98df4128a11caaabfda1f37b6e80ce65",
   "language": "python",
   "display_name": "Python 3.9.7 ('EIL')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}